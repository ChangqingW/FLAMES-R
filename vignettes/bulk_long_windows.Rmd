---
title: "Vignette for FLAMES Bulk on Windows"
author: "Oliver Voogd"
package: FLAMES                
output: BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{Vignette for FLAMES Bulk on Windows}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Windows FLAMES Bulk Data Pipeline
Windows is capable of running the Bulk FLAMES pipeline however, as the genome alignment in FLAMES is handled using minimap2, these functions are not able to be run on a Windows OS. This vignette provides a workflow for running the package primarily on Windows, with the required non-Windows functions being handled by a supported system - either MacOS or a Linux distrubution.

In order to run the FLAMES bulk pipeline on Windows, ensure that the arguments do_genome_align and do_read_realign are set to FALSE. This will run the FLAMES pipeline, without the initial read alignment using Minimap2 step, and the later read realignment using Minimap2 step.
```{r eval=FALSE}
bulk_long_pipeline <- function(..., do_genome_align=FALSE, do_read_realign=FALSE) {
```

Alternatively, the FLAMES pipeline can be manually executed using exported functions from the FLAMES package, and minimap2 alignment and realignmentcan be performed externally to complete the full pipeline.

This process for manual execution with external alignment is outlined below.

## Manual execution of FLAMES pipeline


### Environment setup
Begin by storing the required variables `annot`, `fastq`, `outdir`, `genome_fa`, in the current workspace. Ensure `outdir` exists, and is writable. More information on the values of these variables can be obtained by executing `?FLAMES::bulk_long_pipeline`. The optional `config_file` variable can also be stored, or the default configuration file, located in the `extdata/` folder in the base level of this packaged can be used.

This vignette uses `BiocFileCache` to download the required variables from an example data set.
Below is the process for creating the BiocFileCache and downloading the required files. The code below is included for demonstration and is not required in order to run the Flames pipeline on Windows.
The downloaded files are stored in a temporary directory.
```{r eval=TRUE, echo=TRUE}
# download required files using BiocFileCache
temp_path <- tempfile()
bfc <- BiocFileCache::BiocFileCache(temp_path, ask=FALSE)
file_url <- 
  "https://raw.githubusercontent.com/OliverVoogd/FlamesR/master/inst/data"
annot <- bfc[[names(BiocFileCache::bfcadd(bfc, "Annotation", paste(file_url, "SIRV_isoforms_multi-fasta-annotation_C_170612a.gtf", sep="/")))]] # [[ notation is used to get the local file path of the downloaded file
genome_fa <- bfc[[names(BiocFileCache::bfcadd(bfc, "Genomefa", paste(file_url, "SIRV_isoforms_multi-fasta_170612a.fasta", sep="/")))]]

# download the two fastq files, move them to a folder to be merged together
fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep="/")))]]
fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep="/")))]]
fastq_dir <- paste(temp_path, "fastq_dir", sep="/") # the downloaded fastq files need to be in a directory to be merged together
dir.create(fastq_dir)
file.copy(c(fastq1, fastq2), fastq_dir)
unlink(c(fastq1, fastq2)) # the original files can be deleted

# setup other environment variables
config_file <- system.file("extdata/SIRV_config_default.json", package="FLAMES") # the configuration file is included with the FLAMES package
outdir <- tempfile() # create a temporary output directory
if (!dir.exists(outdir)) {
    dir.create(outdir)
}
# remove this
temp_path
```

```{r eval=TRUE, echo=FALSE, results='hide'}
# download files generated using minimap2 (these files need to be generated by the user on a system with access to Minimap2. More information is in the section [Genome Alignment](#genome-alignment-using-minimap2))
genome_bam <- paste0(temp_path, "/align2genome.bam")
file.rename(bfc[[names(BiocFileCache::bfcadd(bfc, "Genome BAM", paste(file_url, "align2genome.bam", sep="/")))]], genome_bam)

genome_index <- paste0(temp_path, "/align2genome.bam.bai")
file.rename(bfc[[names(BiocFileCache::bfcadd(bfc, "Genome BAM Index", paste(file_url, "align2genome.bam.bai", sep="/")))]], genome_index)

realign_bam <- paste0(temp_path, "/realign2genome.bam")
file.rename(bfc[[names(BiocFileCache::bfcadd(bfc, "Realign BAM", paste(file_url, "realign2transcript.bam", sep="/")))]], realign_bam)

realign_index <- paste0(temp_path, "/realign2genome.bam.bai")
file.rename(bfc[[names(BiocFileCache::bfcadd(bfc, "Realign BAM Index", paste(file_url, "realign2transcript.bam.bai", sep="/")))]], realign_index)
```

After these are stored, all fastq files located in the directory `fastq` can be merged by running the below code.
```{r eval=TRUE}
library(FLAMES)
infq <- paste(outdir, "merged.fastq.gz", sep="/")
bc_file <- paste(outdir, "pseudo_barcode_annotation.csv", sep="/")

# run the merge_bulk_fastq function as preprocessing
merge_bulk_fastq(fastq_dir, bc_file, infq)
```

A few intermediate files and variables need to be created before the pipeline can proceed:
```{r eval=TRUE}
# setup of internal arguments which hold output files and intermediate files
isoform_gff3 = paste(outdir, "isoform_annotated.gff3", sep="/")
isoform_gff3_f = paste(outdir, "isoform_annotated.filtered.gff3", sep="/")
FSM_anno_out = paste(outdir, "isoform_FSM_annotation.csv", sep="/")
raw_splice_isoform = paste(outdir, "splice_raw.gff3", sep="/")
tss_tes_stat = paste(outdir, "tss_tes.bedgraph", sep="/")
transcript_fa = paste(outdir, "transcript_assembly.fa", sep="/")
transcript_fa_idx = paste(outdir, "transcript_assembly.fa.fai", sep="/")
tmp_bam = paste(outdir, "tmp.align.bam", sep="/")
tmp_bed = paste(outdir, "tmp.splice_anno.bed12", sep="/")
tr_cnt_csv = paste(outdir, "transcript_count.csv.gz", sep="/")
tr_badcov_cnt_csv = paste(outdir, "transcript_count.bad_coverage.csv.gz", sep="/")

# default value for downsample ratio
downsample_ratio = 1
```
The JSON configuration file should also be loaded into R, using: 
```{r eval=TRUE}
config <- parse_json_config(config_file)
```
If a FLAMES configuration file doesn't exist, one can be created using user specified values, and loaded into R using the function `FLAMES::create_config()`. For more information on the contents of the FLAMES JSON configuration file, and for the input parameters to `create_config()`, run `?FLAMES::create_config()`.

An example of the default FLAMES config file can be found in `extdata/SIRV_config_default.json`. Using `?write_config` will also give a description of the parameters stored in the JSON configuration file.


### FLAMES Execution


#### Genome Alignment Using Minimap2
If genome alignment is required, this should be performed on a system with access to minimap2. The code required to run this is provided below. This code should **not** be run on a Windows system. After this is executed and resulting data transfered to this workspace, the Windows FLAMES bulk pipeline can proceed. 
All required variables for this section should be transferred to the system with minimap2, the code executed below inside an R session using FLAMES, and finally the resulting file BAM file and BAM index file should be returned to the original system and R workspace, and the path to the BAM file should be stored as `genome_bam`, with the related index file being in the same directory as `genome_bam`.
```{r eval=FALSE}
# below code must be run with access to minimap2
tmp_bed <- paste(outdir, "tmp.splice_anno.bed12", sep=.Platform$file.sep)
tmp_bam <- paste(outdir, "tmp.align.bam", sep=.Platform$file.sep)
```
The next line, which converts the annotation file to a bed12 file should only be run if the `config$alignment_parameters$use_junctions flag` is `TRUE`. The example dataset provided requires `config$alignment_parameters$use_junctions` to be `TRUE`.
```{r eval=FALSE}
# if config$alignment_parameters$use_junctions is TRUE
gff3_to_bed12(minimap2_dir, annot, tmp_bed) # minimap2_dir is a folder containing minimap2
```
Then, the minimap2 process can be called, and cleanup performed.
```{r eval=FALSE}
minimap2_align(minimap2_dir, genome_fa, infq, tmp_bam,
    no_flank=config$alignment_parameters$no_flank, bed12_junc=if (config$alignment_parameters$use_junctions) tmp_bed else NULL)

samtools_sort_index(tmp_bam, genome_bam)
file.remove(tmp_bam)
```
Again, the next step is only required if `config$alignment_parameters$use_junctions` is `TRUE`.
```{r eval=FALSE}
# if config$use_junctions is TRUE
file.remove(tmp_bed)
```

After executing this code on a system with access to minimap2, the file `genome_bam` and related index file with extension `.bam.bai` should be returned to the original system, and it's file path loaded into the original R session. `genome_bam` is required for later pipeline steps.

#### Isoform Identification
Next, the annotation file in gff3 format needs to be parsed and loaded into R.
```{r eval=TRUE}
gff3 <- parse_gff_tree(annot)
remove_similar_tr(gff3$gene_to_transcript, gff3$transcript_to_exon)
```
Then, if isoform identification is required, the below code block should be executed.
```{r eval=TRUE}
transcript_to_junctions = list()
for (tr in names(gff3$transcript_to_exon)) {
  transcript_to_junctions[[tr]] = blocks_to_junctions(gff3$transcript_to_exon[[tr]])
}

gene_dict <- get_gene_flat(gff3$gene_to_transcript, gff3$transcript_to_exon)
chr_to_blocks <- get_gene_blocks(gene_dict, gff3$chr_to_gene, gff3$gene_to_transcript)
group_bam2isoform(genome_bam, isoform_gff3, tss_tes_stat, "", chr_to_blocks,
    gene_dict, transcript_to_junctions, gff3$transcript_dict, genome_fa,
    config=config$isoform_parameters, downsample_ratio=downsample_ratio,
    raw_gff3=if (config$global_parameters$generate_raw_isoform) raw_splice_isoform else NULL)
```
Following isoform identification, the isoform gff3 file created from the above call to `group_bam2isoform` needs to be parsed and loaded into R. Finally, we can write the transcript sequences from the isoform file to an output file.
```{r eval=TRUE}
gff3_isoform <- parse_gff_tree(isoform_gff3)

if (!config$realign_parameters$use_annotation) gff3 = NULL
get_transcript_seq(genome_fa, transcript_fa, gff3_isoform$chr_to_gene, gff3_isoform$transcript_dict,
        gff3_isoform$gene_to_transcript, gff3_isoform$transcript_to_exon, ref_dict=gff3)
```


#### Read Realignment
If read realignment is required, this should again be done on a system with access to minimap2. The code below details how this is accomplished, using functions from the FLAMES package. This step requires the files `transcript_fa`, and `infq`, created from prior steps in the pipeline. As with initial read alignment, these should be transferred to a system with access to minimap2, and the resulting file `realign_bam` and related index file transferred back to the current workspace, so the final pipeline step can be completed.
```{r eval=FALSE}
tmp_bam <- paste(outdir, "tmp.align.bam", sep=.Platform$file.sep)
minimap2_tr_align(minimap2_dir, transcript_fa, infq, tmp_bam)
samtools_sort_index(tmp_bam, realign_bam)
file.remove(tmp_bam)
```
The file realign_bam and the index file (`realign_bam.bai`) should be returned back to the original system, and it's file path loaded into the same R session, as it is required for the final FLAMES step. The variable `realign_bam` needs to contain the path to the transferred bam file, which needs to be in the same directory as it's related index file. 


#### Transcript Quantification
Finally, transcript quantification can be performed, as required:
```{r eval=TRUE, results='hide'}
parse_realign <- parse_realigned_bam(realign_bam, transcript_fa_idx,
    config$isoform_parameters$Min_sup_cnt,
    config$transcript_counting$min_tr_coverage,
    config$transcript_counting$min_read_coverage,
    bc_file=bc_file)
    tr_cnt = wrt_tr_to_csv(parse_realign$bc_tr_count_dict, gff3_isoform$transcript_dict, tr_cnt_csv, gff3$transcript_dict, config$global_parameters$has_UMI)
    wrt_tr_to_csv(parse_realign$bc_tr_badcov_count_dict, gff3_isoform$transcript_dict, tr_badcov_cnt_csv, gff3$transcript_dict, config$global_parameters$has_UMI)
    annotate_filter_gff(isoform_gff3, annot, isoform_gff3_f, FSM_anno_out, tr_cnt, config$isoform_parameters$Min_sup_cnt)
```
The directory `outdir` now contains several output files returned from this pipeline. The output files generated by this pipeline are:

\itemize{
  \item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SummarizedExperiment)}
  \item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SummarizedExperiment)}
  \item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
  \item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
  \item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
  \item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
 }
 
 
 The function `FLAMES::bulk_long_pipeline()`, which this vignette provides an implementation of for the Windows OS returns some of the data provided by this output files as a SummarizedExperiment object, for easy integration with other R packages. The below code provides a basic way to created this SummarizedExperiment object.
```{r eval=TRUE}
counts <- utils::read.csv(paste0(outdir, "/transcript_count.csv.gz"))
annot <- utils::read.table(paste0(outdir, "/isoform_annotated.filtered.gff3"))
colnames(annot) <- c("SequenceID", "Source", "Feature", "Start", "End", "Score", "Strand", "Phase", "Attributes")
mdata <- list("Annotations"=annot, "OutputFiles"=
                    list("transcript_assembly"=paste0(outdir, "/transcript_assembly.fa"),
                        "align2genome"=paste0(outdir, "/align2genome.bam"),
                        "realign2transcript"=paste0(outdir, "/realign2transcript.bam"),
                        "tss_tes"=paste0(outdir, "/tss_tes.bedgraph")))
se <- SummarizedExperiment::SummarizedExperiment(list("Flames Bulk"=counts),
                            metadata=mdata)
se
```

#### Session Info
```{r echo=FALSE}
sessionInfo()
```