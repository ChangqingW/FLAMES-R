---
title: "FLAMES"
author: "Oliver Voogd"
package: FLAMES
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{FLAMES} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
bibliography: ref.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# FLAMES

The FLAMES package provides a framework for performing single-cell and bulk read full-length analysis of mutations and splicing. FLAMES performs cell barcode and UMI assignment from nanopore reads as well as semi-supervised isoform detection and quantification. FLAMES is designed to be an easy and quick to use, powerful workflow for isoform detection and quantification, splicing analysis and mutation detection, and seeks to overcome the limitations of other tools, such as an inability to process single cell data, and a focus on cell barcode and UMI assignment.

```{r workflow, echo=FALSE, fig.align='center', fig.cap='FLAMES pipeline workflow summary'}
knitr::include_graphics(system.file("images/FLAMESpipeline-01.png", package="FLAMES"))
```

Input to FLAMES are fastq files generated from the long-read platform. Using the cell barcode annotation obtained from short-read data as the reference, the pipeline identifies and trims cell barcodes/UMI sequences from the long reads. After barcode assignment, all reads are aligned to the relevant genome to obtain a draft read alignment. The draft alignment is then polished and grouped to generate a consensus transcript assembly. All reads are aligned again using the transcript assembly as the reference and quantified. 

Figure \@ref(fig:workflow) provides a high level overview of the main steps in the FLAMES pipeline. The optional arguments on the left are colour coded to associate with the specific step that they apply to.

For read alignment and realignment, FLAMES uses minimap2, a versatile alignment program for aligning sequences against a reference database [@minimap2]. This software needs to be downloaded prior to using the FLAMES pipeline, and can be found at [https://github.com/lh3/minimap2](https://github.com/lh3/minimap2).

However, this software is not available to Windows users. If a user wishes to use the FLAMES pipeline without access to minimap2, please refer to the vignette `Vignette for FLAMES on Windows`, which provides instructions for running the pipeline on Windows, which is also applicable to any system without minimap2 installed.

### Should anything else be added for further details?

# FLAMES Execution

This vignette will detail the process of running the FLAMES pipeline. It uses the bulk data pipeline (`bulk_long_pipeline`) as an example, however this vignette will be useful for those running the other FLAMES entry point, the single cell pipeline (`sc_long_pipeline`).

### Environment setup
To get started, the pipeline needs access to a gene annotation file in GFF3 or GTF format, a directory containing one or more FASTQ files (which will be merged as pre-processing), a genome FASTA file, as well as the file path to minimap2, and the file path to the directory to hold output files.

For this vignette, these files are downloaded from GitHub using BiocFileCache.
```{r eval=TRUE, echo=TRUE}
# download required files using BiocFileCache
temp_path <- tempfile()
bfc <- BiocFileCache::BiocFileCache(temp_path, ask=FALSE)
file_url <- 
  "https://raw.githubusercontent.com/OliverVoogd/FLAMESData/master/data"
annot <- bfc[[names(BiocFileCache::bfcadd(bfc, "Annotation", 
                                          paste(file_url, 
                                                "SIRV_isoforms_multi-fasta-annotation_C_170612a.gtf", 
                                                sep="/")))]] # [[ notation is used to get the local file path of the downloaded file
genome_fa <- bfc[[names(BiocFileCache::bfcadd(bfc, 
                                              "Genomefa", 
                                              paste(file_url, 
                                                    "SIRV_isoforms_multi-fasta_170612a.fasta", 
                                                    sep="/")))]]

# download the two fastq files, move them to a folder to be merged together
fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep="/")))]]
fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep="/")))]]
fastq_dir <- paste(temp_path, "fastq_dir", sep="/") # the downloaded fastq files need to be in a directory to be merged together
dir.create(fastq_dir)
file.copy(c(fastq1, fastq2), fastq_dir)
unlink(c(fastq1, fastq2)) # the original files can be deleted

# setup other environment variables
config_file <- system.file("extdata/SIRV_config_default.json", package="FLAMES") # the configuration file is included with the FLAMES package
outdir <- tempfile() # create a temporary output directory
if (!dir.exists(outdir)) {
    dir.create(outdir)
}
```

The optional argument `config_file` can be given to both `bulk_long_pipeline` and `sc_long_pipeline` in order to customise the execution of the pipelines. It is expected to be a JSON file, and an example can be found at `r system.file("extdata/SIRV_config_default.json", package="FLAMES")`. This JSON file is used in absence of both the argument `config_file` and any alteration of the other optional pipeline arguments.

If `config_file` is not given, the pipeline can instead be customised by altering any of the optional arguments the pipeline allows. These customisations are then stored in a JSON file saved in the specified out directory, which allows for easier reproduction of pipeline execution. More information on the optional arguments at the contents of the JSON configuration file can be found by running `?create_config` and `?bulk_long_pipeline`.

This vignette uses the default configuration file.

### FLAMES execution
Once the environment has been setup, the pipeline can be executed by running:
```{r eval=FALSE}
library(FLAMES)
summarizedExperiment <- bulk_long_pipeline(annot=annot, fastq=fastq_dir, outdir=temp_path, 
                                           genome_fa=genome_fa, minimap2_dir=mm2_dir,
                                           config_file = config_file)
```

### FLAMES termination
The directory `outdir` now contains several output files returned from this pipeline. The output files generated by this pipeline are:

\itemize{
  \item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SummarizedExperiment)}
  \item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SummarizedExperiment)}
  \item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
  \item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
  \item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
  \item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
 }

The pipeline also returns a SummarizedExperiment or SingleCellExperiment object, depending on the pipeline run, containing the data from `transcript_count.csv.gz`and `isoform_annotated.filtered.gff3`. This SummarizedExperiment (or SingleCellExperiment) object meerly contains the same data as present in the `outdir` directory, and is given to simplify the process of reading the transcript count matrix and annotation data back into R, for further analysis.


## FLAMES on Windows
Due to FLAMES requiring minimap2 to complete the pipeline, the straight FLAMES pipeline functions `bulk_long_pipeline` and `sc_long_pipeline` won't run on a Windows OS. To overcome this issue, the vignette 'Vignette for FLAMES on Windows' describes the alternate method of running the FLAMES pipelines, which requires acccess to minimap2 on an external system

# Session Info
``` {r echo=FALSE}
utils::sessionInfo()
```

# References