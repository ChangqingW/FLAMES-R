#' Pipeline for bulk long read RNA-seq data processing
#'
#' @md
#'
#' @description Semi-supervised isofrom detection and annotation for long read data.
#' This variant is meant for bulk samples. Specific parameters can be configured in
#' the config file (see \code{\link{create_config}}), input files are specified via
#' arguments.
#'
#' @details
#' By default FLAMES use minimap2 for read alignment. After the genome alignment step (\code{do_genome_align}), FLAMES summarizes the alignment for each read by grouping reads
#' with similar splice junctions to get a raw isoform annotation (\code{do_isoform_id}). The raw isoform
#' annotation is compared against the reference annotation to correct potential splice site
#' and transcript start/end errors. Transcripts that have similar splice junctions
#' and transcript start/end to the reference transcript are merged with the
#' reference. This process will also collapse isoforms that are likely to be truncated
#' transcripts. If \code{isoform_id_bambu} is set to \code{TRUE}, \code{bambu::bambu} will be used to generate the updated annotations.
#' Next is the read realignment step (\code{do_read_realign}), where the sequence of each transcript from the update annotation is extracted, and
#' the reads are realigned to this updated \code{transcript_assembly.fa} by minimap2. The
#' transcripts with only a few full-length aligned reads are discarded.
#' The reads are assigned to transcripts based on both alignment score, fractions of
#' reads aligned and transcript coverage. Reads that cannot be uniquely assigned to
#' transcripts or have low transcript coverage are discarded. The UMI transcript
#' count matrix is generated by collapsing the reads with the same UMI in a similar
#' way to what is done for short-read scRNA-seq data, but allowing for an edit distance
#' of up to 2 by default. Most of the parameters, such as the minimal distance to splice site and minimal percentage of transcript coverage
#' can be modified by the JSON configuration file (\code{config_file}).
#'
#' @param config_file Path to the JSON configuration file. See \code{\link{create_config}} for creating one.
#' @param outdir Path to the output directory. If it does not exist, it will be created.
#' @param fastq Path to the FASTQ file or a directory containing FASTQ files. Each file
#'   will be processed as an individual sample.
#' @param annotation The file path to the annotation file in GFF3 / GTF format.
#' @param genome_fa The file path to the reference genome in FASTA format.
#' @param minimap2 (optional) The path to the minimap2 binary. If not provided, FLAMES will
#'   use a copy from bioconda via \code{basilisk}.
#' @param samtools (optional) The path to the samtools binary. If not provided, FLAMES will
#'   use a copy from bioconda via \code{basilisk}.
#' @param k8 (optional) The path to the k8 binary to run paftools.js from minimap2. If not
#'   provided, FLAMES will use a copy from bioconda via \code{basilisk}.
#'
#' @return A \code{FLAMES.Pipeline} object. The pipeline could be run using \code{\link{run_FLAMES}}, and / or resumed using \code{\link{resume_FLAMES}}.
#'
#' @seealso
#' \code{\link{create_config}} for creating a configuration file,
#' \code{\link{SingleCellPipeline}} for single cell pipelines,
#' \code{\link{MultiSampleSCPipeline}} for multi sample single cell pipelines.
#'
#' @importFrom utils file_test
#'
#' @examples
#' # download example data
#' temp_path <- tempfile()
#' bfc <- BiocFileCache::BiocFileCache(temp_path, ask = FALSE)
#' file_url <-
#'   "https://raw.githubusercontent.com/OliverVoogd/FLAMESData/master/data"
#' fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep = "/")))]]
#' fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep = "/")))]]
#' annotation <- bfc[[names(BiocFileCache::bfcadd(bfc, "annot.gtf", paste(file_url, "SIRV_isoforms_multi-fasta-annotation_C_170612a.gtf", sep = "/")))]]
#' genome_fa <- bfc[[names(BiocFileCache::bfcadd(bfc, "genome.fa", paste(file_url, "SIRV_isoforms_multi-fasta_170612a.fasta", sep = "/")))]]
#' fastq_dir <- paste(temp_path, "fastq_dir", sep = "/") # the downloaded fastq files need to be in a directory to be merged together
#' dir.create(fastq_dir)
#' file.copy(c(fastq1, fastq2), fastq_dir)
#' unlink(c(fastq1, fastq2)) # the original files can be deleted
#' outdir <- tempfile()
#' dir.create(outdir)
#'
#' ppl <- BulkPipeline(
#'   fastq = fastq_dir, annotation = annotation, genome_fa = genome_fa,
#'   config_file = create_config(outdir, type = "sc_3end", threads = 1, no_flank = TRUE),
#'   outdir = outdir
#' )
#' ppl <- run_FLAMES(ppl) # run the pipeline
#' experiment(ppl) # get the result as SummarizedExperiment
#'
#' @export
BulkPipeline <- function(config_file, outdir, fastq, annotation, genome_fa, minimap2, samtools, k8) {
  pipeline <- new("FLAMES.Pipeline")
  config <- check_arguments(annotation, fastq, genome_bam = NULL, outdir, genome_fa, config_file)$config

  if (!dir.exists(outdir)) {
    dir.create(outdir)
    message(sprintf("Output directory (%s) did not exist, created.", outdir))
  }

  if (length(fastq) == 1 && utils::file_test("-d", fastq)) {
    fastq <- list.files(fastq, pattern = "\\.(fastq|fq)(\\.gz)?$", full.names = TRUE)
  } else if (!all(utils::file_test("-f", fastq))) {
    stop("fastq must be a valid path to a folder or a FASTQ file")
  }
  if (is.null(names(fastq))) {
    names(fastq) <- gsub("\\.(fastq|fq)(\\.gz)?$", "", basename(fastq))
  }
  names(fastq) <- make.unique(names(fastq), sep = "_")

  steps <- c(
    "genome_alignment", "isoform_identification",
    "read_realignment", "transcript_quantification"
  )
  steps <- config$pipeline_parameters[paste0("do_", steps)] |>
    unlist() |>
    setNames(steps)
  message("Configured steps: \n", paste0("\t", names(steps), ": ", steps, collapse = "\n"))


  # assign slots
  ## inputs
  pipeline@config <- config
  pipeline@outdir <- outdir
  pipeline@fastq <- fastq
  pipeline@annotation <- annotation
  pipeline@genome_fa <- genome_fa

  ## outputs
  # metadata
  pipeline@genome_bam <- file.path(outdir, paste0(names(fastq), "_", "align2genome.bam"))
  pipeline@transcriptome_bam <- file.path(outdir, paste0(names(fastq), "_", "realign2transcript.bam"))
  pipeline@transcriptome_assembly <- file.path(outdir, "transcript_assembly.fa")

  ## binaries
  if (missing(minimap2) || !is.character(minimap2)) {
    minimap2 <- find_bin("minimap2")
    if (is.na(minimap2)) {
      stop("minimap2 not found, please make sure it is installed and provide its path as the minimap2 argument")
    }
  }
  pipeline@minimap2 <- minimap2
  if (missing(k8) || !is.character(k8)) {
    k8 <- find_bin("k8")
    if (is.na(k8)) {
      stop("k8 not found, please make sure it is installed and provide its path as the k8 argument")
    }
  }
  pipeline@k8 <- k8
  if (missing(samtools) || !is.character(samtools)) {
    samtools <- find_bin("samtools")
  }
  if (is.na(samtools)) {
    message("samtools not found, will use Rsamtools package instead")
  }
  pipeline@samtools <- samtools
  ##

  ## pipeline state
  pipeline@steps <- steps
  pipeline@completed_steps <- setNames(
    rep(FALSE, length(steps)), names(steps)
  )
  # TODO: add resume option
  # validate if e.g. genome_bam exists, skip genome alignment step

  return(pipeline)
}

setGeneric("prerun_check", function(pipeline, overwrite = FALSE) {
  standardGeneric("prerun_check")
})
setMethod("prerun_check", "FLAMES.Pipeline", function(pipeline, overwrite = FALSE) {
  # return TRUE for run_FLAMES to proceed
  # return FALSE for run_FLAMES to stop gracefully, when all steps are completed
  # stop() when pipeline is partially completed and user does not want to overwrite
  if (all(pipeline@completed_steps)) {
    message("All steps have already been completed.")
    if (overwrite) {
      warning("Re-running pipeline to overwrite existing results.")
      return(TRUE)
    } else {
      message("Pipeline is already completed. Set overwrite = TRUE to re-run.")
      return(FALSE)
    }
  } else if (any(pipeline@completed_steps)) {
    message("Some steps have already been completed.")
    if (overwrite) {
      warning("Re-running pipeline to overwrite existing results.")
      return(TRUE)
    } else {
      # TODO: implement resuming and prompt user to resume
      stop("Pipeline is partially completed. Please set overwrite = TRUE to proceed.")
    }
  } else {
    # nothing done yet, proceed
    return(TRUE)
  }
})

#' Execute a single step of the FLAMES pipeline
#'
#' @description This function runs the specified step of the FLAMES pipeline.
#'
#' @param pipeline A FLAMES.Pipeline object.
#' @param step The step to run. One of "barcode_demultiplex", "genome_alignment",
#'   "gene_quantification", "isoform_identification", "read_realignment", or
#'  "transcript_quantification".
#' @return An updated FLAMES.Pipeline object.
#'
#' @seealso
#' \code{\link{run_FLAMES}} to run the entire pipeline.
#' \code{\link{resume_FLAMES}} to resume a pipeline from the last completed step.
#'
#' @examples
#' pipeline <- example_pipeline("BulkPipeline")
#' pipeline <- run_step(pipeline, "genome_alignment")
#'
#' @export
setGeneric("run_step", function(pipeline, step) {
  standardGeneric("run_step")
})
#' @rdname run_step
#' @export
setMethod("run_step", "FLAMES.Pipeline", function(pipeline, step) {
  start_time <- Sys.time()
  message(sprintf("Running step: %s", step))
  pipeline <- switch(step,
    barcode_demultiplex = barcode_demultiplex(pipeline),
    genome_alignment = genome_alignment(pipeline),
    gene_quantification = gene_quantification(pipeline),
    isoform_identification = isoform_identification(pipeline),
    read_realignment = read_realignment(pipeline),
    transcript_quantification = transcript_quantification(pipeline),
    stop(sprintf("Unknown step: %s", step))
  )
  end_time <- Sys.time()
  pipeline@completed_steps[step] <- TRUE
  pipeline@durations[step] <- difftime(end_time, start_time, units = "secs")
  return(pipeline)
})

#' Execute a FLAMES pipeline
#'
#' @description This function runs the FLAMES pipeline. It will run all steps in the pipeline.
#' @param pipeline A FLAMES.Pipeline object.
#' @return An updated FLAMES.Pipeline object.
#' @seealso
#' \code{\link{resume_FLAMES}} to resume a pipeline from the last completed step.
#' @examples
#' pipeline <- example_pipeline("BulkPipeline")
#' pipeline <- run_FLAMES(pipeline)
#' @export
setGeneric("run_FLAMES", function(pipeline) {
  standardGeneric("run_FLAMES")
})
#' @rdname run_FLAMES
#' @export
setMethod("run_FLAMES", "FLAMES.Pipeline", function(pipeline) {
  if (!prerun_check(pipeline, overwrite = FALSE)) {
    return(pipeline)
  }

  for (step in names(which(pipeline@steps))) {
    # S4 objects are immutable
    # Need R6 for passing by reference
    pipeline <- tryCatch(
      run_step(pipeline, step),
      error = function(e) {
        warning(sprintf("Error in step %s: %s, pipeline stopped.", step, e$message))
        pipeline@last_error <- list(
          step = step,
          error = e,
          traceback = capture.output(traceback())
        )
        return(pipeline)
      }
    )
    if (!pipeline@completed_steps[step]) {
      break
    }
  }
  return(pipeline)
})

#' Resume a FLAMES pipeline
#'
#' @description This function resumes a FLAMES pipeline by running configured
#' but unfinished steps.
#' @param pipeline A FLAMES.Pipeline object.
#' @return An updated FLAMES.Pipeline object.
#' @seealso
#' \code{\link{run_FLAMES}} to run the entire pipeline.
#' @examples
#' pipeline <- example_pipeline("BulkPipeline")
#' pipeline <- run_step(pipeline, "genome_alignment")
#' pipeline <- resume_FLAMES(pipeline)
#' @export
setGeneric("resume_FLAMES", function(pipeline) {
  standardGeneric("resume_FLAMES")
})
#' @rdname resume_FLAMES
#' @export
setMethod("resume_FLAMES", "FLAMES.Pipeline", function(pipeline) {
  configured_steps <- pipeline@completed_steps[pipeline@steps]
  unfinished_steps <- names(which(!configured_steps))
  if (length(unfinished_steps) == 0) {
    message("All steps have already been completed.")
    return(pipeline)
  } else {
    message("Resuming pipeline from step: ", unfinished_steps[1])
    for (step in unfinished_steps) {
      pipeline <- tryCatch(
        run_step(pipeline, step),
        error = function(e) {
          warning(sprintf("Error in step %s: %s, pipeline stopped.", step, e$message))
          pipeline@last_error <- list(
            step = step,
            error = e,
            traceback = capture.output(traceback())
          )
          return(pipeline)
        }
      )
      if (!pipeline@completed_steps[step]) {
        break
      }
    }
    return(pipeline)
  }
})

# Getters and setters

#' Get pipeline results
#'
#' @description This function returns the results of the pipeline as a
#' \code{SummarizedExperiment} object, a \code{SingleCellExperiment} object, or a
#' list of \code{SingleCellExperiment} objects, depending on the pipeline type.
#' @param pipeline A FLAMES.Pipeline object.
#' @return A \code{SummarizedExperiment} object, a \code{SingleCellExperiment} object,
#' or a list of \code{SingleCellExperiment} objects.
#' @examples
#' pipeline <- example_pipeline(type = "BulkPipeline")
#' pipeline <- run_FLAMES(pipeline)
#' se <- experiment(pipeline)
#' @export
setGeneric("experiment", function(pipeline) {
  standardGeneric("experiment")
})
#' @rdname experiment
#' @export
setMethod("experiment", "FLAMES.Pipeline", function(pipeline) {
  pipeline@experiment
})

# individual steps as methods
# dummy methods
setGeneric("barcode_demultiplex", function(pipeline) {
  standardGeneric("barcode_demultiplex")
})
setMethod("barcode_demultiplex", "FLAMES.Pipeline", function(pipeline) {
  stop("Barcode demultiplexing is only implemented for single cell pipelines (SingleCellPipeline() and MultiSampleSCPipeline())")
})
setGeneric("gene_quantification", function(pipeline) {
  standardGeneric("gene_quantification")
})
setMethod("gene_quantification", "FLAMES.Pipeline", function(pipeline) {
  # todo: implement gene quantification for bulk pipelines
  stop("Gene quantification is not implemented for bulk pipelines yet")
})

setGeneric("genome_alignment_raw", function(pipeline, fastqs) {
  standardGeneric("genome_alignment_raw")
})
setMethod("genome_alignment_raw", "FLAMES.Pipeline", function(pipeline, fastqs) {
  minimap2_args <- c(
    "-ax", "splice", "-k14", "--secondary=no", # "-y",
    "-t", pipeline@config$pipeline_parameters$threads,
    "--seed", pipeline@config$pipeline_parameters$seed
  )
  if (pipeline@config$alignment_parameters$no_flank) {
    minimap2_args <- base::append(minimap2_args, "--splice-flank=no")
  }

  # k8 paftools.js gff2bend gff > bed12
  paftoolsjs <- system.file("paftools.js", package = "FLAMES")
  if (pipeline@config$alignment_parameters$use_junctions) {
    bed_file <- tempfile(tmpdir = pipeline@outdir, fileext = ".bed")
    paftoolsjs_status <- base::system2(
      command = pipeline@k8,
      args = c(paftoolsjs, "gff2bed", pipeline@annotation, ">", bed_file)
    )
    if (!is.null(base::attr(paftoolsjs_status, "status")) && base::attr(paftoolsjs_status, "status") != 0) {
      stop(sprintf(
        "Error running %s\nAre you using NCBI GFF3? It is not well supported by minimap2's paftools.js, see https://github.com/lh3/minimap2/issues/422",
        paste(c(pipeline@k8, paftoolsjs, "gff2bed", pipeline@annotation, ">", bed_file), collapse = " ")
      ))
    }
    minimap2_args <- base::append(minimap2_args, c("--junc-bed", bed_file, "--junc-bonus", "1"))
  }

  res <- lapply(
    seq_along(fastqs),
    function(i) {
      if (!is.null(names(fastqs))) {
        sample <- names(fastqs)[i]
      } else {
        sample <- fastqs[i]
      }
      message(sprintf("Aligning sample %s -> %s", sample, pipeline@genome_bam[i]))
      minimap2_align(
        fq_in = fastqs[i],
        fa_file = pipeline@genome_fa,
        config = pipeline@config,
        outfile = pipeline@genome_bam[i],
        minimap2_args = minimap2_args,
        sort_by = "coordinates",
        minimap2 = pipeline@minimap2,
        samtools = pipeline@samtools,
        threads = pipeline@config$pipeline_parameters$threads
      )
    }
  )
  if (!is.null(names(fastqs))) {
    names(res) <- names(fastqs)
  }
  unlink(bed_file)
  pipeline@metadata$genome_alignment <- res
  return(pipeline)
})
setGeneric("genome_alignment", function(pipeline) {
  standardGeneric("genome_alignment")
})
setMethod("genome_alignment", "FLAMES.Pipeline", function(pipeline) {
  genome_alignment_raw(
    pipeline = pipeline,
    fastqs = pipeline@fastq
  )
})

setGeneric("isoform_identification", function(pipeline) {
  standardGeneric("isoform_identification")
})
setMethod("isoform_identification", "FLAMES.Pipeline", function(pipeline) {
  if (pipeline@config$pipeline_parameters$bambu_isoform_identification) {
    novel_isoform_annotation <- find_isoform_bambu(
      annotation = pipeline@annotation,
      genome_fa = pipeline@genome_fa,
      genome_bam = pipeline@genome_bam,
      outdir = pipeline@outdir,
      config = pipeline@config
    )
  } else {
    novel_isoform_annotation <- find_isoform_flames(
      annotation = pipeline@annotation,
      genome_fa = pipeline@genome_fa,
      genome_bam = pipeline@genome_bam,
      outdir = pipeline@outdir,
      config = pipeline@config
    )
  }
  pipeline@novel_isoform_annotation <- novel_isoform_annotation
  annotation_to_fasta(
    isoform_annotation = novel_isoform_annotation,
    genome_fa = pipeline@genome_fa,
    outfile = pipeline@transcriptome_assembly
  )
  return(pipeline)
})

setGeneric("read_realignment_raw", function(pipeline, include_tags = FALSE, sort_by, fastqs) {
  standardGeneric("read_realignment_raw")
})
setMethod(
  "read_realignment_raw", "FLAMES.Pipeline",
  function(pipeline, include_tags = FALSE, sort_by, fastqs) {
    if (pipeline@config$pipeline_parameters$oarfish_quantification) {
      minimap2_args <- c(
        "--eqx", "-N", "100", "-ax", "map-ont",
        "-t", pipeline@config$pipeline_parameters$threads,
        "--seed", pipeline@config$pipeline_parameters$seed
      )
    } else {
      minimap2_args <- c(
        "-ax", "map-ont", "-p", "0.9", "--end-bonus", "10", "-N", "3",
        "-t", pipeline@config$pipeline_parameters$threads,
        "--seed", pipeline@config$pipeline_parameters$seed
      )
    }
    if (include_tags) {
      minimap2_args <- base::append(minimap2_args, "-y")
    }

    if (!file.exists(pipeline@transcriptome_assembly)) {
      if (!pipeline@steps["isoform_identification"]) {
        message("Using reference annotation for transcriptome assembly.")
        annotation_to_fasta(
          isoform_annotation = pipeline@annotation,
          genome_fa = pipeline@genome_fa,
          outfile = pipeline@transcriptome_assembly
        )
      } else {
        stop("Isoform identification step configured but transcriptome assembly file does not exist, aborting realignment.")
      }
    }

    res <- lapply(
      seq_along(fastqs),
      function(i) {
        if (!is.null(names(fastqs))) {
          sample <- names(fastqs)[i]
        } else {
          sample <- fastqs[i]
        }
        message(sprintf("Realigning sample %s -> %s", sample, pipeline@transcriptome_bam[i]))
        minimap2_align(
          fq_in = fastqs[i],
          fa_file = pipeline@transcriptome_assembly,
          config = pipeline@config,
          outfile = pipeline@transcriptome_bam[i],
          minimap2_args = minimap2_args,
          sort_by = sort_by,
          minimap2 = pipeline@minimap2,
          samtools = pipeline@samtools,
          threads = pipeline@config$pipeline_parameters$threads
        )
      }
    )
    if (!is.null(names(fastqs))) {
      names(res) <- names(fastqs)
    }
    pipeline@metadata$read_realignment <- res
    return(pipeline)
  }
)

setGeneric("read_realignment", function(pipeline, include_tags = FALSE) {
  standardGeneric("read_realignment")
})
setMethod("read_realignment", "FLAMES.Pipeline", function(pipeline, include_tags = FALSE) {
  sort_by <- ifelse(
    pipeline@config$pipeline_parameters$oarfish_quantification,
    "none",
    "coordinates"
  )
  read_realignment_raw(
    pipeline = pipeline,
    include_tags = include_tags,
    sort_by = sort_by,
    fastqs = pipeline@fastq
  )
})
setGeneric("transcript_quantification", function(pipeline, reference_only) {
  standardGeneric("transcript_quantification")
})
setMethod("transcript_quantification", "FLAMES.Pipeline", function(pipeline, reference_only) {
  if ((!missing(reference_only) && reference_only) || is.na(pipeline@novel_isoform_annotation)) {
    annotation <- pipeline@annotation
  } else {
    annotation <- pipeline@novel_isoform_annotation
  }
  pipeline_class <- switch(
    class(pipeline),
    "FLAMES.Pipeline" = "bulk",
    "FLAMES.SingleCellPipeline" = "sc_single_sample",
    "FLAMES.MultiSampleSCPipeline" = "sc_multi_sample"
  )
  # TODO: refactor quantify_transcript to take file paths from pipeline
  x <- quantify_transcript(
    annotation = annotation,
    outdir = pipeline@outdir,
    config = pipeline@config,
    pipeline = pipeline_class,
    samples = names(pipeline@fastq)
  )
  if (is.list(x) & pipeline_class == "sc_multi_sample") {
    pipeline@experiments <- x
  } else {
    pipeline@experiment <- x
  }
  return(pipeline)
})

# Deprecated functions
#' Pipeline for bulk long read RNA-seq data processing (deprecated)
#' 
#' @description This function is deprecated. Use \code{\link{BulkPipeline}} instead.
#'
#' @param annotation The file path to the annotation file in GFF3 / GTF format.
#' @param fastq Path to the FASTQ file or a directory containing FASTQ files. Each file
#'   will be processed as an individual sample.
#' @param outdir Path to the output directory. If it does not exist, it will be created.
#' @param genome_fa The file path to the reference genome in FASTA format.
#' @param minimap2 (optional) The path to the minimap2 binary. If not provided, FLAMES will
#'   use a copy from bioconda via \code{basilisk}.
#' @param k8 (optional) The path to the k8 binary to run paftools.js from minimap2. If not
#'   provided, FLAMES will use a copy from bioconda via \code{basilisk}.
#' @param config_file Path to the JSON configuration file. See \code{\link{create_config}} for creating one.
#'
#' @return A \code{SummarizedExperiment} object containing the transcript counts.
#' @seealso
#' \code{\link{BulkPipeline}} for the new pipeline function.
#' \code{\link{SingleCellPipeline}} for single cell pipelines,
#' \code{\link{MultiSampleSCPipeline}} for multi sample single cell pipelines.
#'
#' @examples
#' temp_path <- tempfile()
#' bfc <- BiocFileCache::BiocFileCache(temp_path, ask = FALSE)
#' file_url <-
#'   "https://raw.githubusercontent.com/OliverVoogd/FLAMESData/master/data"
#' # download the required fastq files, and move them to new folder
#' fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep = "/")))]]
#' fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep = "/")))]]
#' annotation <- bfc[[names(BiocFileCache::bfcadd(bfc, "annot.gtf", paste(file_url, "SIRV_isoforms_multi-fasta-annotation_C_170612a.gtf", sep = "/")))]]
#' genome_fa <- bfc[[names(BiocFileCache::bfcadd(bfc, "genome.fa", paste(file_url, "SIRV_isoforms_multi-fasta_170612a.fasta", sep = "/")))]]
#' fastq_dir <- paste(temp_path, "fastq_dir", sep = "/") # the downloaded fastq files need to be in a directory to be merged together
#' dir.create(fastq_dir)
#' file.copy(c(fastq1, fastq2), fastq_dir)
#' unlink(c(fastq1, fastq2)) # the original files can be deleted
#' outdir <- tempfile()
#' dir.create(outdir)
#' se <- bulk_long_pipeline(
#'   annotation = annotation, fastq = fastq_dir, outdir = outdir, genome_fa = genome_fa,
#'   config_file = create_config(outdir, type = "sc_3end", threads = 1, no_flank = TRUE)
#' )
#' @export
bulk_long_pipeline <- function(
    annotation, fastq, outdir, genome_fa,
    minimap2 = NULL, k8 = NULL, config_file) {
  message("bulk_long_pipeline() is deprecated. Use BulkPipeline() instead.")
  pipeline <- BulkPipeline(
    config_file = config_file,
    outdir = outdir,
    fastq = fastq,
    annotation = annotation,
    genome_fa = genome_fa,
    minimap2 = minimap2,
    k8 = k8
  )
  pipeline <- run_FLAMES(pipeline)
  saveRDS(pipeline, file.path(outdir, "pipeline.rds"))
  message("Pipeline saved to ", file.path(outdir, "pipeline.rds"))
  if (length(pipeline@last_error) == 0) {
    return(experiment(pipeline))
  } else {
    warning("Returning pipeline object instead of experiment due to errors.")
    message("You can resume the pipeline after resolving the errors with resume_FLAMES(pipeline)")
    return(pipeline)
  }
}
