% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bulk_long_pipeline.R
\name{bulk_long_pipeline}
\alias{bulk_long_pipeline}
\title{Pipeline for Bulk Data}
\usage{
bulk_long_pipeline(
  annot,
  fastq,
  in_bam = NULL,
  outdir,
  genome_fa,
  minimap2_dir = NULL,
  downsample_ratio = 1,
  config_file = NULL,
  do_genome_align = TRUE,
  do_isoform_id = TRUE,
  do_read_realign = TRUE,
  do_transcript_quanti = TRUE,
  gen_raw_isoform = TRUE,
  has_UMI = FALSE,
  MAX_DIST = 10,
  MAX_TS_DIST = 100,
  MAX_SPLICE_MATCH_DIST = 10,
  min_fl_exon_len = 40,
  Max_site_per_splice = 3,
  Min_sup_cnt = 10,
  Min_cnt_pct = 0.01,
  Min_sup_pct = 0.2,
  strand_specific = 1,
  remove_incomp_reads = 5,
  use_junctions = TRUE,
  no_flank = TRUE,
  use_annotation = TRUE,
  min_tr_coverage = 0.75,
  min_read_coverage = 0.75
)
}
\arguments{
\item{annot}{gene annotations file in gff3  format}

\item{fastq}{the directory containing the fastq input files to merge into one, \code{merged.fastq.gz}. If \code{merged.fastq.gz} already
exists, the fastq files are not merged and the existing merged file is used.}

\item{in_bam}{optional BAM file which replaces fastq directory argument. This skips the genome alignment and
realignment steps}

\item{outdir}{directory to store all output files.}

\item{genome_fa}{genome fasta file.}

\item{minimap2_dir}{directory containing minimap2, k8 and paftools.js program.
k8 and paftools.js are used to convert gff3 to bed12.}

\item{downsample_ratio}{downsampling ratio if performing downsampling analysis.}

\item{config_file}{JSON configuration file. If specified, \code{config_file} overrides
all configuration parameters}

\item{do_genome_align}{Boolean. Specifies whether to run the genome alignment step. \code{TRUE} is recommended}

\item{do_isoform_id}{Boolean. Specifies whether to run the isoform identification step. \code{TRUE} is recommended}

\item{do_read_realign}{Boolean. Specifies whether to run the read realignment step. \code{TRUE} is recommended}

\item{do_transcript_quanti}{Boolean. Specifies whether to run the transcript quantification step. \code{TRUE} is recommended}

\item{gen_raw_isoform}{Boolean.}

\item{has_UMI}{Boolean. Specifies if the data contains UMI.}

\item{MAX_DIST}{Maximum distance allowed when merging splicing sites in isoform consensus clustering.}

\item{MAX_TS_DIST}{Maximum distance allowed when merging transcript start/end position in isoform consensus clustering.}

\item{MAX_SPLICE_MATCH_DIST}{Maximum distance allowed when merging splice site called from the data and the reference annotation.}

\item{min_fl_exon_len}{Minimum length for the first exon outside the gene body in reference annotation. This is to correct the alignment artifact}

\item{Max_site_per_splice}{Maximum transcript start/end site combinations allowed per splice chain}

\item{Min_sup_cnt}{Minimum number of read support an isoform decrease this number will significantly increase the number of isoform detected.}

\item{Min_cnt_pct}{Minimum percentage of count for an isoform relative to total count for the same gene.}

\item{Min_sup_pct}{Minimum percentage of count for an splice chain that support a given transcript start/end site combination.}

\item{strand_specific}{1, -1 or 0. 1 indicates if reads are in the same
strand as mRNA, -1 indicates reads are reverse complemented, 0 indicates
reads are not strand specific.}

\item{remove_incomp_reads}{The strenge of truncated isoform filtering. larger number means more stringent filtering.}

\item{use_junctions}{whether to use known splice junctions to help correct the alignment results}

\item{no_flank}{Boolean. for synthetic spike-in data. refer to Minimap2 document for detail}

\item{use_annotation}{Boolean. whether to use reference to help annotate known isoforms}

\item{min_tr_coverage}{Minimum percentage of isoform coverage for a read to be aligned to that isoform}

\item{min_read_coverage}{Minimum percentage of read coverage for a read to be uniquely aligned to that isoform}
}
\value{
\code{bulk_long_pipeline} returns a SummarizedExperiment object, containing a count
matrix as an assay, gene annotations under metadata, as well as a list of the other
output files generated by the pipeline. The pipeline also outputs a number of output
files into the given \code{outdir} directory. These output files generated by the pipeline are:
\itemize{
\item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SummarizedExperiment)}
\item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SummarizedExperiment)}
\item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
\item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
\item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
\item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
}
}
\description{
Semi-supervised isofrom detection and annotation for long read data.
This variant is meant for bulk samples. Specific parameters relating to
analysis can be changed either through function arguments, or through a
configuration JSON file.
}
\details{
By default FLAMES use minimap2 for read alignment. After the genome alignment step (\code{do_genome_align}), FLAMES summarizes the alignment for each read by grouping reads
with similar splice junctions to get a raw isoform annotation (\code{do_isoform_id}). The raw isoform
annotation is compared against the reference annotation to correct potential splice site
and transcript start/end errors. Transcripts that have similar splice junctions
and transcript start/end to the reference transcript are merged with the
reference. This process will also collapse isoforms that are likely to be truncated
transcripts. Next is the read realignment step (\code{do_read_realign}), where the sequence of each polished transcript is extracted and used as
the updated reference. The reads are realigned to this reference by minimap2. The
transcripts with only a few full-length aligned reads are discarded.
The reads are assigned to transcripts based on both alignment score, fractions of
reads aligned and transcript coverage. Reads that cannot be uniquely assigned to
transcripts or have low transcript coverage are discarded. The UMI transcript
count matrix is generated by collapsing the reads with the same UMI in a similar
way to what is done for short-read scRNA-seq data, but allowing for an edit distance
of up to 2 by default. Most of the parameters, such as the minimal distance to splice site and minimal percentage of transcript coverage
can be modified by the JSON configuration file (\code{config_file}).

The default parameters can be changed either through the function
arguments are through the configuration JSON file \code{config_file}. the \code{pipeline_parameters}
section specifies which steps are to be executed in the pipeline - by default, all
steps are executed. The \code{isoform_parameters} section affects isoform detection - key
parameters include:
\itemize{
\item{\code{Min_sup_cnt}}{ which causes transcripts with less reads aligned than
it's value to be discarded}
\item{\code{MAX_TS_DIST}}{ which merges transcripts with the same intron
chain and TSS/TES distace less than \code{MAX_TS_DIST}}
\item{\code{strand_specific}}{ which specifies if reads are in the same strand as the mRNA (1),
or the reverse complemented (-1) or not strand specific (0), which results in
strand information being based on reference annotation.}
}
}
\examples{
# download the two fastq files, move them to a folder to be merged together
temp_path <- tempfile()
bfc <- BiocFileCache::BiocFileCache(temp_path, ask=FALSE)
file_url <- 
    "https://raw.githubusercontent.com/OliverVoogd/FLAMESData/master/data"
# download the required fastq files, and move them to new folder
fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep="/")))]]
fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep="/")))]]
fastq_dir <- paste(temp_path, "fastq_dir", sep="/") # the downloaded fastq files need to be in a directory to be merged together
dir.create(fastq_dir)
file.copy(c(fastq1, fastq2), fastq_dir)
unlink(c(fastq1, fastq2)) # the original files can be deleted

\dontrun{
# run the FLAMES bulk pipeline, using the downloaded files
se <- bulk_long_pipeline(annot=system.file("extdata/SIRV_anno.gtf", package="FLAMES"), 
                   fastq=fastq_dir,
                   outdir=tempdir(), genome_fa=system.file("extdata/SIRV_genomefa.fasta", package="FLAMES"),
                   config_file=system.file("extdata/SIRV_config_default.json", package="FLAMES"))
}
# OR
# run the FLAMES single cell pipeline
#sce <- sc_long_pipeline(annot, fastq, NULL, outdir, genome_fa, match_barcode=FALSE, config+file=config)
}
\seealso{
\code{\link[=sc_long_pipeline]{sc_long_pipeline()}} for single cell data,
\code{\link[=SummarizedExperiment]{SummarizedExperiment()}} for how data is outputted
}
