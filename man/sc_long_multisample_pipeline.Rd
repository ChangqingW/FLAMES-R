% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sc_long_multisample_pipeline.R
\name{sc_long_multisample_pipeline}
\alias{sc_long_multisample_pipeline}
\title{Pipeline for Multi-sample Single Cell Data}
\usage{
sc_long_multisample_pipeline(
  annotation,
  fastqs,
  outdir,
  genome_fa,
  minimap2_dir = NULL,
  reference_csv,
  match_barcode = TRUE,
  config_file = NULL
)
}
\arguments{
\item{annotation}{The file path to gene annotations file in gff3  format}

\item{fastqs}{A vector containing the paths to each fastq files. If \code{in_bams} is not provided, this argument can also
be provided as the path to the folder containing the fastq files. Each fastq file will be treated as a sample.}

\item{outdir}{The path to directory to store all output files.}

\item{genome_fa}{The file path to genome fasta file.}

\item{minimap2_dir}{Path to the directory containing minimap2, if it is not in PATH. Only required if either or both of
\code{do_genome_align} and \code{do_read_realign} are \code{TRUE}.}

\item{reference_csv}{The file path to the reference csv used for demultiplexing}

\item{match_barcode}{Boolean; specifies if demultiplexing should be performed using \code{FLAMES::match_cell_barcode_cpp}}

\item{config_file}{File path to the JSON configuration file. If specified, \code{config_file} overrides
all configuration parameters}

\item{in_bams}{Optional vector containing file paths the  bam files to use instead of fastq file (skips initial alignment step).
The order of the bam files need to mach the order in \code{fastqs}.}
}
\value{
\code{sc_long_pipeline} returns a SingleCellExperiment object, containing a count
matrix as an assay, gene annotations under metadata, as well as a list of the other
output files generated by the pipeline. The pipeline also outputs a number of output
files into the given \code{outdir} directory. These output files generated by the pipeline are:
\itemize{
\item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SingleCellExperiment)}
\item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SingleCellExperiment)}
\item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
\item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
\item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
\item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
}
}
\description{
Semi-supervised isoform detection and annotation for long read data.
This variant is for multi-sample single cell data. By default, this pipeline demultiplexes input
fastq data (\code{match_cell_barcode = TRUE}). Specific parameters relating to
analysis can be changed either through function arguments, or through a
configuration JSON file.
}
\details{
By default FLAMES use minimap2 for read alignment. After the genome alignment step (\code{do_genome_align}), FLAMES summarizes the alignment for each read in every sample by grouping reads
with similar splice junctions to get a raw isoform annotation (\code{do_isoform_id}). The raw isoform
annotation is compared against the reference annotation to correct potential splice site
and transcript start/end errors. Transcripts that have similar splice junctions
and transcript start/end to the reference transcript are merged with the
reference. This process will also collapse isoforms that are likely to be truncated
transcripts. If \code{isoform_id_bambu} is set to \code{TRUE}, \code{bambu::bambu} will be used to generate the updated annotations (Not implemented for multi-sample yet).
Next is the read realignment step (\code{do_read_realign}), where the sequence of each transcript from the update annotation is extracted, and
the reads are realigned to this updated \code{transcript_assembly.fa} by minimap2. The
transcripts with only a few full-length aligned reads are discarded (Not implemented for multi-sample yet).
The reads are assigned to transcripts based on both alignment score, fractions of
reads aligned and transcript coverage. Reads that cannot be uniquely assigned to
transcripts or have low transcript coverage are discarded. The UMI transcript
count matrix is generated by collapsing the reads with the same UMI in a similar
way to what is done for short-read scRNA-seq data, but allowing for an edit distance
of up to 2 by default. Most of the parameters, such as the minimal distance to splice site and minimal percentage of transcript coverage
can be modified by the JSON configuration file (\code{config_file}).

The default parameters can be changed either through the function
arguments are through the configuration JSON file \code{config_file}. the \code{pipeline_parameters}
section specifies which steps are to be executed in the pipeline - by default, all
steps are executed. The \code{isoform_parameters} section affects isoform detection - key
parameters include:
\itemize{
\item{\code{Min_sup_cnt}}{ which causes transcripts with less reads aligned than
it's value to be discarded}
\item{\code{MAX_TS_DIST}}{ which merges transcripts with the same intron
chain and TSS/TES distace less than \code{MAX_TS_DIST}}
\item{\code{strand_specific}}{ which specifies if reads are in the same strand as the mRNA (1),
or the reverse complemented (-1) or not strand specific (0), which results in
strand information being based on reference annotation.}
}
}
\examples{
# download the two fastq files, move them to a folder to be merged together
temp_path <- tempfile()
bfc <- BiocFileCache::BiocFileCache(temp_path, ask=FALSE)
file_url <- 
    "https://raw.githubusercontent.com/OliverVoogd/FLAMESData/master/data"
# download the required fastq files, and move them to new folder
fastq1 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq1", paste(file_url, "fastq/sample1.fastq.gz", sep="/")))]]
fastq2 <- bfc[[names(BiocFileCache::bfcadd(bfc, "Fastq2", paste(file_url, "fastq/sample2.fastq.gz", sep="/")))]]
fastq_dir <- paste(temp_path, "fastq_dir", sep="/") # the downloaded fastq files need to be in a directory to be merged together
dir.create(fastq_dir)
file.copy(c(fastq1, fastq2), fastq_dir)
unlink(c(fastq1, fastq2)) # the original files can be deleted

\dontrun{
    # run the FLAMES bulk pipeline, using the downloaded files
outdir <- tempdir()
se <- bulk_long_pipeline(annot=system.file("extdata/SIRV_anno.gtf", package="FLAMES"), 
                   fastq=fastq_dir, outdir=outdir, 
                   genome_fa=system.file("extdata/SIRV_genomefa.fasta", package="FLAMES"),
                   config_file=system.file("extdata/SIRV_config_default.json", package="FLAMES"))
}

\donttest{
    # create SummarizedExperiment from output folder
    se_2 <- create_se_from_dir(outdir = outdir, annot = system.file("extdata/SIRV_anno.gtf", package="FLAMES"))
    # Could also be use to create SummarizedExperiment from the Python FLAMES output folder
    sce <- create_se_from_dir(outdir = sce_outdir, annot = system.file("extdata/SIRV_anno.gtf", package="FLAMES"))
}
# OR
# run the FLAMES single cell pipeline
#sce <- sc_long_pipeline(annot, fastq, NULL, outdir, genome_fa, match_barcode=FALSE, config+file=config)
}
\seealso{
\code{\link[=bulk_long_pipeline]{bulk_long_pipeline()}} for bulk long data,
\code{\link[=SingleCellExperiment]{SingleCellExperiment()}} for how data is outputted
}
